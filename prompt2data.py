# -*- coding: utf-8 -*-
"""Prompt2Data.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1h8HEW4mfzG8I-AVYuuX_lM9NO7H6j24q
"""

!pip install -q requests torch bitsandbytes transformers sentencepiece accelerate openai gradio

from google.colab import drive, userdata
from huggingface_hub import login
from transformers import AutoTokenizer, BitsAndBytesConfig, AutoModelForCausalLM, TextStreamer
import torch
from openai import OpenAI
from IPython.display import display, update_display, Markdown, Image, Audio

import gradio as gr
import gc
import os

hf_token = userdata.get('HF_TOKEN_1')
login(hf_token, add_to_git_credential = True)

openai_api_key = userdata.get('HF_OPENAI')
openai= OpenAI(api_key = openai_api_key)

LLAMA = "meta-llama/Meta-Llama-3.1-8B-Instruct"

quant_config = BitsAndBytesConfig(
    load_in_4bit = True,
    bnb_4bit_use_double_quant = True,
    bnb_4bit_compute_type = torch.bfloat16,
    bnb_4bit_quant_type = 'nf4'
)

system_prompt = """
You are an expert synthetic data generator AI.
Your task is to create realistic, structured datasets in JSON or CSV format
based purely on the user's description of their desired dataset.

Follow these principles strictly:

1. **Data Schema Inference**
   - Automatically infer meaningful column names, data types, and relationships from the user’s description.
   - Ensure column names use clear, consistent naming conventions (snake_case or camelCase).

2. **Data Realism**
   - Generate realistic, contextually appropriate values.
   - Use plausible ranges, types, and patterns (e.g., ages between 1–100, prices as decimals, valid dates, etc.).
   - If the domain involves categorical data (like gender, crop type, or sport), use relevant and diverse categories.

3. **Output Format Control**
   - Output **only the dataset**, without any explanations or extra commentary.
   - If the user requests `JSON`, output an array of JSON objects.
   - If the user requests `CSV`, output valid CSV with a header row.
   - Do not include markdown formatting (no triple backticks, etc.).

4. **Data Quantity**
   - Generate the requested number of rows.
   - Ensure that all rows are consistent in structure (no missing keys or inconsistent fields).

5. **Consistency and Cleanliness**
   - No nulls unless explicitly requested.
   - All numeric columns should be consistent in type (no mixing strings with numbers).
   - Avoid repetition — each row should feel unique and realistic.

6. **Field-Specific Intelligence**
   - For medical data: realistic names, patient IDs, diagnoses, ages, and treatment durations.
   - For agriculture: crops, rainfall, yield, fertilizer type, soil quality.
   - For education: students, subjects, scores, attendance, grades.
   - For sports: players, teams, scores, match dates, statistics.
   - For other domains: infer suitable fields based on context.

7. **Formatting Strictness**
   - JSON must be valid and parsable.
   - CSV must be comma-separated with consistent column order.

Example:

If the user says:
"Generate a dataset of 10 students with names, ages, and scores in mathematics."

You should output (for JSON):
[
  {"student_id": "S001", "name": "Amit Sharma", "age": 16, "math_score": 88},
  {"student_id": "S002", "name": "Priya Nair", "age": 15, "math_score": 92},
  ...
]

Or (for CSV):
student_id,name,age,math_score
S001,Amit Sharma,16,88
S002,Priya Nair,15,92
...

---

Remember:
- Never include explanations, notes, or commentary.
- The dataset **alone** should be the output.
- If the user gives a vague description, use your best inference and create useful columns relevant to that domain.
"""

def user_prompt(prompt):
    user_prompt = ""
    user_prompt += "You are an advanced AI specialized in generating realistic and structured synthetic datasets.\n\n"

    user_prompt += "User Description:\n"
    user_prompt += f"\"{prompt}\"\n\n"

    user_prompt += "Your objectives:\n"
    user_prompt += "1. **Schema Inference** – Automatically determine the most logical column names and data types based on the user's description.\n"
    user_prompt += "   - If the user specifies column names, follow them exactly.\n"
    user_prompt += "   - If not, intelligently infer suitable columns relevant to the context or domain.\n"
    user_prompt += "2. **Data Quantity** – By default, generate a moderately sized dataset (around 50–100 rows).\n"
    user_prompt += "   - Only change the number of rows if the user explicitly requests more or fewer.\n"
    user_prompt += "3. **Data Realism** – Ensure the data is contextually accurate, diverse, and coherent.\n"
    user_prompt += "   - Numeric values should stay within realistic ranges.\n"
    user_prompt += "   - Text or categorical values should reflect domain relevance (e.g., names, crops, schools, teams, etc.).\n"
    user_prompt += "4. **Structure & Consistency** – Every row must follow the same schema with no missing or mismatched fields.\n"
    user_prompt += "   - Maintain consistent data types across all rows.\n"
    user_prompt += "   - Avoid repetition — entries should look naturally varied.\n"
    user_prompt += "5. **Output Formatting** –\n"
    user_prompt += "   - If JSON is expected, output a single valid JSON array of objects.\n"
    user_prompt += "   - If CSV is expected, output a clean CSV with headers and properly aligned rows.\n"
    user_prompt += "   - Do not include markdown, explanations, or text outside the dataset.\n"
    user_prompt += "6. **Domain Awareness** – Adapt based on the topic:\n"
    user_prompt += "   - Medical → patients, age, diagnosis, treatment, recovery_days, etc.\n"
    user_prompt += "   - Agriculture → crop, fertilizer_type, rainfall, yield, soil_quality, etc.\n"
    user_prompt += "   - Education → student, subject, score, attendance, grade, etc.\n"
    user_prompt += "   - Sports → player, team, match_date, score, performance_stats, etc.\n"
    user_prompt += "   - If the domain is not clear, make a balanced general-purpose dataset.\n"
    user_prompt += "7. **Behavior** –\n"
    user_prompt += "   - Stay concise, structured, and realistic.\n"
    user_prompt += "   - Never include markdown, commentary, or explanations in your output.\n"
    user_prompt += "   - Output only the dataset — nothing else.\n"

    user_prompt += "\nYour response must contain ONLY the dataset output. No introductions, explanations, or summaries."

    return user_prompt

def messages_for(prompt):
  messages = [
      {'role':'system','content':system_prompt},
      {'role':'user','content':user_prompt(prompt)}
  ]

  return messages

def generate_dataset(model_name, prompt):
    messages = messages_for(prompt)
    tokenizer= AutoTokenizer.from_pretrained(model_name, trust_remote_code = True)
    tokenizer.pad_token = tokenizer.eos_token
    inputs = tokenizer.apply_chat_template(messages_for(prompt),return_tensors = 'pt', add_generation_prompt = True).to('cuda')
    model = AutoModelForCausalLM.from_pretrained(model_name, device_map = 'auto', quantization_config = quant_config)
    output = model.generate(inputs, max_new_tokens = 5000)
    result = tokenizer.decode(output[0], skip_special_tokens=True)

    del model, inputs, tokenizer, output
    gc.collect()
    torch.cuda.empty_cache()

    return result

"""## Saving the Dataset Generated"""

from google.colab import files
import time

drive.mount('/content/drive/')

SAVE_DIR = '/content/drive/MyDrive/Colab Notebooks/HF- Gen_AI/Datasets_Generated'
os.makedirs(SAVE_DIR, exist_ok=True)

def gen_and_save(model_name, prompt,file_format):
  result = generate_dataset(model_name, prompt)

  timestamp = int(time.time())
  filename = f"synthetic_dataset_{timestamp}.{file_format.lower()}"
  file_path = os.path.join(SAVE_DIR, filename)

  with open(file_path, "w", encoding="utf-8") as f:
        f.write(result)

  message = f"✅ Dataset successfully saved at:\n{file_path}"
  return result[:2500], message

"""## UI"""

gr.Interface(
    fn = gen_and_save,
    inputs = [gr.Dropdown([LLAMA], label = 'Select Your Model', value = LLAMA),gr.Textbox(label = 'Enter the Description', lines = 6),gr.Dropdown(['CSV','JSON'],label = 'Select the Result Format',value="CSV")],
    outputs = [gr.Markdown(label = "Result :"),gr.Markdown(label = 'Location :')],
    allow_flagging = 'never',
).launch(debug = True)